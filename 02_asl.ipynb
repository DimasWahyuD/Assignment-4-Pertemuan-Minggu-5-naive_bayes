{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "02_asl.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DimasWahyuD/Assignment-4-Pertemuan-Minggu-5-naive_bayes/blob/main/02_asl.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GxHYqClsDj-a"
      },
      "source": [
        "<img src=\"./images/DLI_Header.png\" style=\"width: 400px;\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YQxoWYhDj-g"
      },
      "source": [
        "# Image Classification of an American Sign Language Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVMhKb-pDj-i"
      },
      "source": [
        "In this section, we will perform the data preparation, model creation, and model training steps we observed in the last section using a different dataset: images of hands making letters in [American Sign Language](http://www.asl.gs/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "acpynC76Dj-k"
      },
      "source": [
        "## Objectives"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqdGkQueDj-m"
      },
      "source": [
        "* Prepare image data for training\n",
        "* Create and compile a simple model for image classification\n",
        "* Train an image classification model and observe the results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DUAbcPoPDj-n"
      },
      "source": [
        "## American Sign Language Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-6uDgUqDj-p"
      },
      "source": [
        "The [American Sign Language alphabet](http://www.asl.gs/) contains 26 letters. Two of those letters (j and z) require movement, so they are not included in the training dataset.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oiOeSVj_Dj-r"
      },
      "source": [
        "<img src=\"./images/asl.png\" style=\"width: 600px;\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h5zMXXmqDj-u"
      },
      "source": [
        "### Kaggle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nk5wEs_WDj-w"
      },
      "source": [
        "This dataset is available from the website [Kaggle](http://www.kaggle.com), which is a fantastic place to find datasets and other deep learning resources. In addition to providing resources like datasets and \"kernels\" that are like these notebooks, Kaggle hosts competitions that you can take part in, competing with others in training highly accurate models.\n",
        "\n",
        "If you're looking to practice or see examples of many deep learning projects, Kaggle is a great site to visit."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AGiQ7rIHDj-z"
      },
      "source": [
        "## Loading the Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFbZeNebDj-0"
      },
      "source": [
        "This dataset is not available via Keras in the same way that MNIST is, so let's learn how to load custom data. By the end of this section we will have `x_train`, `y_train`, `x_valid`, and `y_valid` variables as before."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gVyHnzvRDj-2"
      },
      "source": [
        "### Reading in the Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXSESSx3Dj-4"
      },
      "source": [
        "The sign language dataset is in [CSV](https://en.wikipedia.org/wiki/Comma-separated_values) (Comma Separated Values) format, the same data structure behind Microsoft Excel and Google Sheets. It is a grid of rows and columns with labels at the top, as seen in the [train](data/asl_data/sign_mnist_train.csv) and [valid](data/asl_data/sign_mnist_valid.csv) datasets (they may take a moment to load).\n",
        "\n",
        "To load and work with the data, we'll be using a library called [Pandas](https://pandas.pydata.org/), which is a highly performant tool for loading and manipulating data. We'll read the CSV files into a format called a [DataFrame](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kXeERG_ODj-6"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQsBvZKbDj-8"
      },
      "source": [
        "Pandas has a [read_csv](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html) method that expects a csv file, and returns a DataFrame:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Yvjus3EDj-9"
      },
      "source": [
        "train_df = pd.read_csv(\"data/asl_data/sign_mnist_train.csv\")\n",
        "valid_df = pd.read_csv(\"data/asl_data/sign_mnist_valid.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UeMOuUsjDj_A"
      },
      "source": [
        "### Exploring the Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "klO2-LGjDj_B"
      },
      "source": [
        "Let's take a look at our data. We can use the [head](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.head.html) method to print the first few rows of the DataFrame. Each row is an image which has a `label` column, and also, 784 values representing each pixel value in the image, just like with the MNIST dataset. Note that the labels currently are numerical values, not letters of the alphabet:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LhbG0CiNDj_C"
      },
      "source": [
        "train_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNPHUWosDj_E"
      },
      "source": [
        "### Extracting the Labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0ctpdyPDj_E"
      },
      "source": [
        "As with MNIST, we would like to store our training and validation labels in `y_train` and `y_valid` variables. Here we create those variables and then delete the labels from our original dataframes, where they are no longer needed:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2YF2pWBUDj_F"
      },
      "source": [
        "y_train = train_df['label']\n",
        "y_valid = valid_df['label']\n",
        "del train_df['label']\n",
        "del valid_df['label']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQmcx0QODj_H"
      },
      "source": [
        "### Extracting the Images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6aPi6HZCDj_H"
      },
      "source": [
        "As with MNIST, we would like to store our training and validation images in `x_train` and `x_valid` variables. Here we create those variables:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8X-ZHXUUDj_I"
      },
      "source": [
        "x_train = train_df.values\n",
        "x_valid = valid_df.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OH6WMOs7Dj_I"
      },
      "source": [
        "### Summarizing the Training and Validation Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZErcJ6KcDj_J"
      },
      "source": [
        "We now have 27,455 images with 784 pixels each for training..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0FUpYD6Dj_K"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZCYQ3JTDj_K"
      },
      "source": [
        "...as well as their corresponding labels:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKToSSZqDj_L"
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W5SjUiT6Dj_M"
      },
      "source": [
        "For validation, we have 7,172 images..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cmB5QTiDj_M"
      },
      "source": [
        "x_valid.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJGhUis5Dj_N"
      },
      "source": [
        "...and their corresponding labels:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jSJxEIU5Dj_N"
      },
      "source": [
        "y_valid.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JB0dFXspDj_O"
      },
      "source": [
        "## Visualizing the Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LOynG59sDj_P"
      },
      "source": [
        "To visualize the images, we will again use the matplotlib library. We don't need to worry about the details of this visualization, but if interested, you can learn more about [matplotlib](https://matplotlib.org/) at a later time.\n",
        "\n",
        "Note that we'll have to reshape the data from its current 1D shape of 784 pixels, to a 2D shape of 28x28 pixels to make sense of the image:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xb4FSNvEDj_P"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(40,40))\n",
        "\n",
        "num_images = 20\n",
        "for i in range(num_images):\n",
        "    row = x_train[i]\n",
        "    label = y_train[i]\n",
        "    \n",
        "    image = row.reshape(28,28)\n",
        "    plt.subplot(1, num_images, i+1)\n",
        "    plt.title(label, fontdict={'fontsize': 30})\n",
        "    plt.axis('off')\n",
        "    plt.imshow(image, cmap='gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxVm9WiCDj_Q"
      },
      "source": [
        "## Exercise: Normalize the Image Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ApCY4rwvDj_R"
      },
      "source": [
        "As we did with the MNIST dataset, we are going to normalize the image data, meaning that their pixel values, instead of being between 0 and 255 as they are currently:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rs3uupgVDj_R"
      },
      "source": [
        "x_train.min()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8gyysZcDj_S"
      },
      "source": [
        "x_train.max()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ChyluhmDj_S"
      },
      "source": [
        "...should be floating point values between 0 and 1. Use the following cell to work. If you get stuck, look at the solution below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KH3E5R9ODj_T"
      },
      "source": [
        "# TODO: Normalize x_train and x_valid."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0FENHJEfDj_T"
      },
      "source": [
        "### Solution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QztOKCaGDj_U"
      },
      "source": [
        "Click on the '...' below to show the solution."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "id": "NhJ4NSxjDj_U"
      },
      "source": [
        "```python\n",
        "x_train = x_train / 255\n",
        "x_valid = x_valid / 255\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFL3Y5eBDj_V"
      },
      "source": [
        "## Exercise: Categorize the Labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pmj9rAIYDj_V"
      },
      "source": [
        "As we did with the MNIST dataset, we are going to categorically encode the labels. Recall that we can use the [keras.utils.to_categorical](https://www.tensorflow.org/api_docs/python/tf/keras/utils/to_categorical) method to accomplish this by passing it the values to encode, and, the number of categories to encode it into. Do your work in the cell below. We have imported `keras` and set the number of categories (24) for you."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3PiXfzWcDj_W"
      },
      "source": [
        "import tensorflow.keras as keras\n",
        "num_classes = 24"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TAUoAOG8Dj_W"
      },
      "source": [
        "# TODO: Categorically encode y_train and y_valid."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxNjJAReDj_X"
      },
      "source": [
        "### Solution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1eA0elvDj_Y"
      },
      "source": [
        "Click on the '...' below to show the solution."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "id": "XPbjVbJvDj_Y"
      },
      "source": [
        "```python\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_valid = keras.utils.to_categorical(y_valid, num_classes)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3qCeAmOFDj_Z"
      },
      "source": [
        "## Exercise: Build the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSfubDMeDj_Z"
      },
      "source": [
        "The data is all prepared, we have normalized images for training and validation, as well as categorically encoded labels for training and validation.\n",
        "\n",
        "For this exercise we are going to build a sequential model. Just like last time, build a model that:\n",
        "* Has a dense input layer. This layer should contain 512 neurons, use the `relu` activation function, and expect input images with a shape of `(784,)`\n",
        "* Has a second dense layer with 512 neurons which uses the `relu` activation function\n",
        "* Has a dense output layer with neurons equal to the number of classes, using the `softmax` activation function\n",
        "\n",
        "Do your work in the cell below, creating a `model` variable to store the model. We've imported the Keras [Sequental](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential) model class and [Dense](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense) layer class to get you started. Reveal the solution below for a hint:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ViiUSgzcDj_a"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWCn8AvbDj_b"
      },
      "source": [
        "# TODO: build a model following the guidelines above."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOWgVtljDj_b"
      },
      "source": [
        "### Solution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WlB3ghkYDj_c"
      },
      "source": [
        "Click on the '...' below to show the solution."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "id": "9zDfTtG8Dj_c"
      },
      "source": [
        "```python\n",
        "model = Sequential()\n",
        "model.add(Dense(units = 512, activation='relu', input_shape=(784,)))\n",
        "model.add(Dense(units = 512, activation='relu'))\n",
        "model.add(Dense(units = num_classes, activation='softmax'))\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mC193HiiDj_d"
      },
      "source": [
        "## Summarizing the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K0Y1-phODj_d"
      },
      "source": [
        "Run the cell below to summarize the model you just created:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gL6epnmFDj_e"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XWu-q7EjDj_e"
      },
      "source": [
        "## Compiling the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7tPg2AtDj_f"
      },
      "source": [
        "We'll [compile](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential#compile) our model with the same options as before, using [categorical crossentropy](https://www.tensorflow.org/api_docs/python/tf/keras/losses/CategoricalCrossentropy) to reflect the fact that we want to fit into one of many categories, and measuring the accuracy of our model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nNbPjbLDj_f"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0Dd4tHuDj_g"
      },
      "source": [
        "## Exercise: Train the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iF1fvr5ADj_g"
      },
      "source": [
        "Use the model's `fit` method to train it for 20 epochs using the training and validation images and labels created above:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLhTVpORDj_h"
      },
      "source": [
        "# TODO: Train the model for 20 epochs."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pS905lhsDj_h"
      },
      "source": [
        "### Solution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSclFSfwDj_h"
      },
      "source": [
        "Click on the '...' below to show the solution."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "id": "8Mi7rJ9bDj_i"
      },
      "source": [
        "```python\n",
        "model.fit(x_train, y_train, epochs=20, verbose=1, validation_data=(x_valid, y_valid))\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xGKCq-nbDj_i"
      },
      "source": [
        "## Discussion: What happened?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULs-PZRcDj_j"
      },
      "source": [
        "We can see that the training accuracy got to a fairly high level, but the validation accuracy was not as high. What happened here?\n",
        "\n",
        "Think about it for a bit before clicking on the '...' below to reveal the answer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "id": "vDXX8dARDj_j"
      },
      "source": [
        "This is an example of the model learning to categorize the training data, but performing poorly against new data that it has not been trained on. Essentially, it is memorizing the dataset, but not gaining a robust and general understanding of the problem. This is a common issue called *overfitting*. We will discuss overfitting in the next two lectures, as well as some ways to address it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bk0bOv61Dj_k"
      },
      "source": [
        "## Summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQPXqZI2Dj_k"
      },
      "source": [
        "In this section you built your own neural network to perform image classification that is quite accurate. Congrats!\n",
        "\n",
        "At this point we should be getting somewhat familiar with the process of loading data (incuding labels), preparing it, creating a model, and then training the model with prepared data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhpzWmIiDj_l"
      },
      "source": [
        "### Clear the Memory\n",
        "Before moving on, please execute the following cell to clear up the GPU memory. This is required to move on to the next notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9pmn71YDj_l"
      },
      "source": [
        "import IPython\n",
        "app = IPython.Application.instance()\n",
        "app.kernel.do_shutdown(True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oPfv0F59Dj_m"
      },
      "source": [
        "## Next"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JD2zfua_Dj_m"
      },
      "source": [
        "Now that you have built some very basic, somewhat effective models, we will begin to learn about more sophisticated models, including *Convolutional Neural Networks*."
      ]
    }
  ]
}